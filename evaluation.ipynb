{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tensorflow.keras.preprocessing import image, image_dataset_from_directory\n",
    "from keras.applications.imagenet_utils import decode_predictions\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "import time\n",
    "import string\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class keras_evaluation:\n",
    "    def __init__(self,data_path):\n",
    "        self.file_path = [data_path+'' + x+'/'+y for x in os.listdir(data_path) for y in os.listdir(data_path+'/'+x)]\n",
    "\n",
    "    def evaluate(self,model_path):\n",
    "        self.model = tf.keras.models.load_model(model_path)\n",
    "        self.model.compile(optimizer='Adam',loss='mse')\n",
    "\n",
    "        pred_list = []\n",
    "        pred_time_list = []\n",
    "        for i in tqdm(self.file_path):\n",
    "            label = i.split('/')[1].split('.')[0]\n",
    "            pred,time_to_predict = self.predict(i)\n",
    "            pred_time_list.append(time_to_predict)\n",
    "            pred_list.append(1) if pred == label else pred_list.append(0)\n",
    "\n",
    "        accuracy = sum(pred_list)/len(pred_list)\n",
    "        avg_pred_time = sum(pred_time_list)/len(pred_time_list)\n",
    "        print(\"Accuracy of the model on {} images is {}\".format(len(self.file_path), accuracy))\n",
    "        print(\"Average prediction time per image was {} \".format(avg_pred_time))\n",
    "\n",
    "        return accuracy,avg_pred_time\n",
    "\n",
    "\n",
    "    def predict(self,image_path):\n",
    "        tik = time.time()\n",
    "        img = image.load_img(image_path,target_size=(224,224))\n",
    "        preprocessed_image = (np.expand_dims(preprocess_input(image.img_to_array(img)),0))#/255\n",
    "\n",
    "        predictions = self.model.predict(preprocessed_image,verbose=False)#,batch_size=1,verbose=False)\n",
    "        tok = time.time() - tik\n",
    "\n",
    "        pred = decode_predictions(predictions)[0][0][0]\n",
    "\n",
    "        return pred,tok\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class tflite_evaluation:\n",
    "    def __init__(self,data_path):\n",
    "        self.file_path = [data_path+'' + x+'/'+y for x in os.listdir(data_path) for y in os.listdir(data_path+'/'+x)]\n",
    "\n",
    "    def evaluate(self,model):\n",
    "        self.model = model\n",
    "        self.load_model()\n",
    "        pred_list = []\n",
    "        pred_time_list = []\n",
    "        for i in tqdm(self.file_path):\n",
    "            label = i.split('/')[1].split('.')[0]\n",
    "            pred,time_to_predict = self.predict(i)\n",
    "            pred_time_list.append(time_to_predict)\n",
    "            pred_list.append(1) if pred == label else pred_list.append(0)\n",
    "\n",
    "        accuracy = sum(pred_list)/len(pred_list)\n",
    "        avg_pred_time = sum(pred_time_list)/len(pred_time_list)\n",
    "        print(\"Accuracy of the model on {} images is {}\".format(len(self.file_path), accuracy))\n",
    "        print(\"Average prediction time per image was {} \".format(avg_pred_time))\n",
    "\n",
    "        return accuracy,avg_pred_time\n",
    "\n",
    "\n",
    "    def predict(self,image_path):\n",
    "        tik = time.time()\n",
    "        img = (image.load_img(image_path,target_size=(224,224)))\n",
    "        preprocessed_image = preprocess_input(image.img_to_array(img))\n",
    "\n",
    "        test_image = np.expand_dims(preprocessed_image, axis=0).astype(np.float32)\n",
    "\n",
    "        input_index = self.interpreter.get_input_details()[0][\"index\"]\n",
    "        output_index = self.interpreter.get_output_details()[0][\"index\"]\n",
    "\n",
    "        self.interpreter.set_tensor(input_index, test_image)\n",
    "        self.interpreter.invoke()\n",
    "        predictions = self.interpreter.get_tensor(output_index)\n",
    "        tok = time.time() - tik\n",
    "\n",
    "        pred = decode_predictions(predictions)[0][0][0]\n",
    "\n",
    "        return pred,tok\n",
    "    \n",
    "    def load_model(self):\n",
    "        self.interpreter = tf.lite.Interpreter(model_path=self.model)\n",
    "        self.interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_evaluation = tflite_evaluation('val/')\n",
    "og_evaluation = keras_evaluation('val/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating Original Pre-trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3925 [00:00<?, ?it/s]2022-10-01 17:53:12.406312: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "100%|██████████| 3925/3925 [02:35<00:00, 25.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on 3925 images is 0.06598726114649682\n",
      "Average prediction time per image was 0.03925239781665195 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.06598726114649682, 0.03925239781665195)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "og_evaluation.evaluate('./Models/mobilenet_v2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3925/3925 [05:10<00:00, 12.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on 3925 images is 0.8300636942675159\n",
      "Average prediction time per image was 0.07886544768218022 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8300636942675159, 0.07886544768218022)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "og_evaluation.evaluate('./Models/resnet_50.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3925/3925 [07:28<00:00,  8.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on 3925 images is 0.7579617834394905\n",
      "Average prediction time per image was 0.11372578444754242 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7579617834394905, 0.11372578444754242)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "og_evaluation.evaluate('./Models/vgg16.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating Dynamic Range Quantized Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3925/3925 [00:36<00:00, 107.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on 3925 images is 0.062420382165605096\n",
      "Average prediction time per image was 0.00885416832699138 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.062420382165605096, 0.00885416832699138)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compressed_evaluation.evaluate('./Models/mobilenet_v2_dynamic_quant.tflite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3925/3925 [02:11<00:00, 29.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on 3925 images is 0.8310828025477707\n",
      "Average prediction time per image was 0.033207292131557584 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8310828025477707, 0.033207292131557584)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compressed_evaluation.evaluate('./Models/resnet_50_dynamic_quant.tflite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3925/3925 [06:55<00:00,  9.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on 3925 images is 0.7597452229299363\n",
      "Average prediction time per image was 0.10519638359167013 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7597452229299363, 0.10519638359167013)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compressed_evaluation.evaluate('Models/vgg16_dynamic_quant.tflite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating Float16 Quantized Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3925/3925 [00:53<00:00, 72.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on 3925 images is 0.06598726114649682\n",
      "Average prediction time per image was 0.013261378828886967 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.06598726114649682, 0.013261378828886967)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compressed_evaluation.evaluate('./Models/mobilenet_v2_f16_quant.tflite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3925/3925 [03:45<00:00, 17.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on 3925 images is 0.8300636942675159\n",
      "Average prediction time per image was 0.05681291148920727 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8300636942675159, 0.05681291148920727)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compressed_evaluation.evaluate('./Models/resnet_50_f16_quant.tflite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3925/3925 [10:00<00:00,  6.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on 3925 images is 0.7579617834394905\n",
      "Average prediction time per image was 0.15209060261963278 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7579617834394905, 0.15209060261963278)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compressed_evaluation.evaluate('./Models/vgg16_f16_quant.tflite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating Int8 Quantized Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3925/3925 [00:58<00:00, 66.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on 3925 images is 0.03159235668789809\n",
      "Average prediction time per image was 0.014842959847419885 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.03159235668789809, 0.014842959847419885)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compressed_evaluation.evaluate('./Models/mobilenet_v2_int8_quant.tflite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3925/3925 [05:12<00:00, 12.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on 3925 images is 0.4807643312101911\n",
      "Average prediction time per image was 0.0793717786460925 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4807643312101911, 0.0793717786460925)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compressed_evaluation.evaluate('./Models/resnet_50_int8_quant.tflite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3925/3925 [18:07<00:00,  3.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on 3925 images is 0.39872611464968155\n",
      "Average prediction time per image was 0.27645560252438683 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.39872611464968155, 0.27645560252438683)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compressed_evaluation.evaluate('./Models/vgg16_int8_quant.tflite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "work",
   "language": "python",
   "name": "work"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cbb4c99ba6a158315ca45ade86b338397709de922c2faeb37289f32131d55cc1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
